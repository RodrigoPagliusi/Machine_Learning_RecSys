{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5a8f68a",
   "metadata": {},
   "source": [
    "# movielens k-fold dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('./')\n",
    "import numpy as np\n",
    "import random as random\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import random\n",
    "\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('./rawdata/ratings.dat', sep = \"::\", header = None,engine = 'python')\n",
    "raw.columns = ['uid', 'sid', 'ratings', 'timestamp']\n",
    "print(raw)\n",
    "raw = raw[['uid', 'sid']]\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785bf9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_items = raw.sid.value_counts()[raw.sid.value_counts() >= 10].reset_index()['index'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c173eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = raw[raw.sid.isin(new_items)]\n",
    "data2 = data2.reset_index()[['uid', 'sid']]\n",
    "print(data2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cb60878",
   "metadata": {},
   "source": [
    "### Reindex by popularity count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5432d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_uid = data2.uid.value_counts().reset_index()\n",
    "pop_uid.columns = ['uid', 'uid_counts']\n",
    "print(pop_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_uid_dict = pop_uid.reset_index()\n",
    "pop_uid_dict = pop_uid_dict[['index', 'uid']]\n",
    "pop_uid_dict.columns = ['new_uid', 'uid']\n",
    "print(pop_uid_dict)\n",
    "pop_uid_dict = dict(zip(pop_uid_dict.uid, pop_uid_dict.new_uid))\n",
    "print(pop_uid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_sid = data2.sid.value_counts().reset_index()\n",
    "pop_sid.columns = ['sid', 'sid_counts']\n",
    "print(pop_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae3473",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_sid_dict = pop_sid.reset_index()\n",
    "pop_sid_dict = pop_sid_dict[['index', 'sid']]\n",
    "pop_sid_dict.columns = ['new_sid', 'sid']\n",
    "print(pop_sid_dict)\n",
    "pop_sid_dict = dict(zip(pop_sid_dict.sid, pop_sid_dict.new_sid))\n",
    "print(pop_sid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data2)\n",
    "data2['uid'] = data2.uid.map(pop_uid_dict).values\n",
    "data2['sid'] = data2.sid.map(pop_sid_dict).values\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82caf5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.sort_values(['uid', 'sid'], ascending = [True, True])\n",
    "print(data2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "080e330b",
   "metadata": {},
   "source": [
    "tmp = data2\n",
    "tmp['one'] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44cbb3b3",
   "metadata": {},
   "source": [
    "sns.heatmap(tmp.pivot_table(index = 'uid', columns = 'sid', values = 'one', fill_value = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10662fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.reset_index()[['uid', 'sid']]\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.reset_index()[['uid', 'sid']]\n",
    "print(all_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f14f9a8a",
   "metadata": {},
   "source": [
    "### Folds Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c6bcfbb",
   "metadata": {},
   "source": [
    "#### Número de K_Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f26864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de Folds a serem gerados\n",
    "num_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(0)\n",
    "\n",
    "fold_1 = all_data.sample(frac = 1/num_folds)\n",
    "fold_1 = fold_1.reset_index()\n",
    "fold_1 = fold_1.drop(columns = ['index'])\n",
    "\n",
    "rest = all_data.merge(fold_1.drop_duplicates(), on=['uid','sid'], how='left', indicator=True)\n",
    "\n",
    "rest = rest[rest['_merge'] == 'left_only']\n",
    "rest = rest.drop(columns = ['_merge'])\n",
    "\n",
    "name = 1\n",
    "\n",
    "for i in range(num_folds - 2):\n",
    "\n",
    "    name += 1\n",
    "    num_folds -= 1\n",
    "\n",
    "    globals()['fold_'+str(name)] = rest.sample(frac = 1/num_folds)\n",
    "    globals()['fold_'+str(name)] = globals()['fold_'+str(name)].reset_index()\n",
    "    globals()['fold_'+str(name)] = globals()['fold_'+str(name)].drop(columns = ['index'])\n",
    "\n",
    "    rest = rest.merge(globals()['fold_'+str(name)].drop_duplicates(), on=['uid','sid'], how='left', indicator=True)\n",
    "\n",
    "    rest = rest[rest['_merge'] == 'left_only']\n",
    "    rest = rest.drop(columns = ['_merge'])\n",
    "\n",
    "name += 1\n",
    "num_folds -= 1\n",
    "\n",
    "globals()['fold_'+str(name)] = rest.sample(frac = 1/num_folds)\n",
    "globals()['fold_'+str(name)] = globals()['fold_'+str(name)].reset_index()\n",
    "globals()['fold_'+str(name)] = globals()['fold_'+str(name)].drop(columns = ['index'])\n",
    "\n",
    "# for i in range(name): print('fold_'+str(i +1) + ' =\\n',globals()['fold_'+str(i + 1)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05c89bbe",
   "metadata": {},
   "source": [
    "### Make negative sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(0)\n",
    "\n",
    "n_user = len(all_data.uid.unique())\n",
    "n_item = len(all_data.sid.unique())\n",
    "\n",
    "item_set = set(list(range(n_item)))\n",
    "neg_sample_df = pd.DataFrame({'uid' : [], 'sid' : []})\n",
    "\n",
    "for user in list(range(n_user)):\n",
    "    true_set = all_data[all_data['uid'] == user]['sid'].values\n",
    "    true_set = set(true_set)\n",
    "    user_neg_samples = item_set - true_set\n",
    "    user_neg_samples = list(user_neg_samples)\n",
    "\n",
    "    list_len = len(user_neg_samples)\n",
    "    user_neg_samples = random.sample(user_neg_samples, 100)\n",
    "    tmp_neg_sample_df = pd.DataFrame({'uid' : [user]*100, 'sid' : user_neg_samples})\n",
    "\n",
    "    neg_sample_df = pd.concat([neg_sample_df, tmp_neg_sample_df])\n",
    "neg_sample_df['uid'] = neg_sample_df['uid'].astype(int)\n",
    "neg_sample_df['sid'] = neg_sample_df['sid'].astype(int)\n",
    "neg_sample_df['type'] = 'neg'\n",
    "neg_sample_df = neg_sample_df.reset_index()[['uid', 'sid', 'type']]\n",
    "# print(neg_sample_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01fde58b",
   "metadata": {},
   "source": [
    "### Training Val Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(name):\n",
    "    train_part = all_data.merge(globals()['fold_'+str(i + 1)].drop_duplicates(), on=['uid','sid'], how='left', indicator=True)\n",
    "    train_part = train_part[train_part['_merge'] == 'left_only']\n",
    "    train_part = train_part.drop(columns = ['_merge'])\n",
    "    globals()['train_fold_'+str(i + 1)] = train_part.sample(frac = 0.75)\n",
    "    globals()['train_fold_'+str(i + 1)] = globals()['train_fold_'+str(i + 1)].reset_index()\n",
    "    globals()['train_fold_'+str(i + 1)] = globals()['train_fold_'+str(i + 1)].drop(columns = ['index'])\n",
    "    # print('train_fold_'+str(i + 1) + ' =\\n',globals()['train_fold_'+str(i + 1)])\n",
    "    globals()['val_fold_'+str(i + 1)] = train_part.merge(globals()['train_fold_'+str(i + 1)].drop_duplicates(), on=['uid','sid'], how='left', indicator=True)\n",
    "    globals()['val_fold_'+str(i + 1)] = globals()['val_fold_'+str(i + 1)][globals()['val_fold_'+str(i + 1)]['_merge'] == 'left_only']\n",
    "    globals()['val_fold_'+str(i + 1)] = globals()['val_fold_'+str(i + 1)].reset_index()\n",
    "    globals()['val_fold_'+str(i + 1)] = globals()['val_fold_'+str(i + 1)].drop(columns = ['index','_merge'])\n",
    "    globals()['val_fold_'+str(i + 1)]['type'] = 'pos'\n",
    "    # print('val_fold_'+str(i + 1) + ' =\\n',globals()['val_fold_'+str(i + 1)])\n",
    "    globals()['val_fold_'+str(i + 1) + '_with_neg'] = pd.concat([globals()['val_fold_'+str(i + 1)], neg_sample_df])\n",
    "    globals()['val_fold_'+str(i + 1) + '_with_neg'] = globals()['val_fold_'+str(i + 1) + '_with_neg'].reset_index()\n",
    "    globals()['val_fold_'+str(i + 1) + '_with_neg'] = globals()['val_fold_'+str(i + 1) + '_with_neg'].drop(columns = ['index'])\n",
    "    # print('val_fold_'+str(i + 1) + '_with_neg' + ' =\\n',globals()['val_fold_'+str(i + 1) + '_with_neg'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d992b18",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35fc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(name):\n",
    "    globals()['test_fold_'+str(i + 1)] = globals()['fold_'+str(i + 1)].copy()\n",
    "    globals()['test_fold_'+str(i + 1)]['type'] = 'pos'\n",
    "    globals()['test_fold_'+str(i + 1)] = globals()['test_fold_'+str(i + 1)].reset_index()[['uid', 'sid', 'type']]\n",
    "    #print('test_fold_'+str(i + 1) + ' =\\n',globals()['test_fold_'+str(i + 1)])\n",
    "    globals()['test_fold_'+str(i + 1) + '_with_neg'] = pd.concat([globals()['test_fold_'+str(i+ 1)], neg_sample_df])\n",
    "    globals()['test_fold_'+str(i + 1) + '_with_neg'] = globals()['test_fold_'+str(i + 1) + '_with_neg'].reset_index()[['uid', 'sid', 'type']]\n",
    "    #print('test_fold_'+str(i + 1) + '_with_neg' + ' =\\n',globals()['test_fold_'+str(i + 1) + '_with_neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93590602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute only once!\n",
    "test_fold_5.loc[-1] = [train_fold_5.iloc[0].values[0],train_fold_5.iloc[0].values[1],'pos']\n",
    "test_fold_5.index = test_fold_5.index + 1\n",
    "test_fold_5.sort_index(inplace = True)\n",
    "test_fold_5_with_neg.loc[-1] = [train_fold_5.iloc[0].values[0],train_fold_5.iloc[0].values[1],'pos']\n",
    "test_fold_5_with_neg.index = test_fold_5_with_neg.index + 1\n",
    "test_fold_5_with_neg.sort_index(inplace = True)\n",
    "train_fold_5 = train_fold_5.drop(index = 0).reset_index().drop(columns = 'index')\n",
    "# print(train_fold_5)\n",
    "# print(test_fold_5)\n",
    "# print(test_fold_5_with_neg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7185298",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c38429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('all_data =\\n',all_data)\n",
    "# print('neg_sample_df =\\n',neg_sample_df)\n",
    "# for i in range(name):\n",
    "#     print('train_fold_'+str(i + 1) + ' =\\n',globals()['train_fold_'+str(i + 1)])\n",
    "#     print('val_fold_'+str(i + 1) + ' =\\n',globals()['val_fold_'+str(i + 1)])\n",
    "#     print('val_fold_'+str(i + 1) + '_with_neg' + ' =\\n',globals()['val_fold_'+str(i + 1) + '_with_neg'])\n",
    "#     print('test_fold_'+str(i + 1) + ' =\\n',globals()['test_fold_'+str(i + 1)])\n",
    "#     print('test_fold_'+str(i + 1) + '_with_neg' + ' =\\n',globals()['test_fold_'+str(i + 1) + '_with_neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ea01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(all_data.shape[0] == train_fold_1.shape[0] + val_fold_1.shape[0] + test_fold_1.shape[0])\n",
    "print(all_data.shape[0] == train_fold_2.shape[0] + val_fold_2.shape[0] + test_fold_2.shape[0])\n",
    "print(all_data.shape[0] == train_fold_3.shape[0] + val_fold_3.shape[0] + test_fold_3.shape[0])\n",
    "print(all_data.shape[0] == train_fold_4.shape[0] + val_fold_4.shape[0] + test_fold_4.shape[0])\n",
    "print(all_data.shape[0] == train_fold_5.shape[0] + val_fold_5.shape[0] + test_fold_5.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2231d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fold_1_with_neg.shape[0] == val_fold_1.shape[0] + neg_sample_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fold_1_with_neg.shape[0] == test_fold_1.shape[0] + neg_sample_df.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04d70ac7",
   "metadata": {},
   "source": [
    "### To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('./processed_csv_folds/all_data.csv', index = False)\n",
    "neg_sample_df.to_csv('./processed_csv_folds/neg_sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(name):\n",
    "    globals()['train_fold_'+str(i+1)].to_csv('./processed_csv_folds/train_fold_'+str(i+1)+'.csv', index = False)\n",
    "    globals()['val_fold_'+str(i+1)].to_csv('./processed_csv_folds/val_fold_'+str(i+1)+'.csv', index = False)\n",
    "    globals()['val_fold_'+str(i+1)+'_with_neg'].to_csv('./processed_csv_folds/val_fold_'+str(i+1)+'_with_neg'+'.csv', index = False)\n",
    "    globals()['test_fold_'+str(i+1)].to_csv('./processed_csv_folds/test_fold_'+str(i+1)+'.csv', index = False)\n",
    "    globals()['test_fold_'+str(i+1)+'_with_neg'].to_csv('./processed_csv_folds/test_fold_'+str(i+1)+'_with_neg'+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214435af",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_pop_total = all_data.uid.value_counts().reset_index()\n",
    "uid_pop_total.columns = ['uid', 'total_counts']\n",
    "\n",
    "sid_pop_total = all_data.sid.value_counts().reset_index()\n",
    "sid_pop_total.columns = ['sid', 'total_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(name):\n",
    "    uid_pop_train = globals()['train_fold_'+str(i+1)].uid.value_counts().reset_index()\n",
    "    uid_pop_train.columns = ['uid', 'train_counts']\n",
    "\n",
    "    sid_pop_train = globals()['train_fold_'+str(i+1)].sid.value_counts().reset_index()\n",
    "    sid_pop_train.columns = ['sid', 'train_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_pop_total.to_csv('./processed_csv_folds/pop_uid_all_data.csv', index = False)\n",
    "sid_pop_total.to_csv('./processed_csv_folds/pop_sid_all_data.csv', index = False)\n",
    "\n",
    "for i in range(name):\n",
    "    uid_pop_train.to_csv('./processed_csv_folds/pop_uid_train_fold_'+str(i+1)+'.csv', index = False)\n",
    "    sid_pop_train.to_csv('./processed_csv_folds/pop_sid_train_fold_'+str(i+1)+'.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c8f19f8",
   "metadata": {},
   "source": [
    "# K-Fold Epoch Negative Sample Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num = all_data['uid'].max() + 1\n",
    "item_num = all_data['sid'].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_samples_data = neg_sample_df[['uid','sid']].copy()\n",
    "neg_samples_data.columns = ['user', 'item']\n",
    "neg_samples_data = neg_samples_data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028df830",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(name):\n",
    "    globals()['train_data_'+str(i+1)] = globals()['train_fold_'+str(i+1)].values.tolist()\n",
    "    globals()['train_mat_'+str(i+1)] = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
    "    for x in globals()['train_data_'+str(i+1)]: globals()['train_mat_'+str(i+1)][x[0], x[1]] = 1.0\n",
    "\n",
    "    globals()['test_data_'+str(i+1)] = globals()['test_fold_'+str(i+1)][['uid','sid']].copy()\n",
    "    globals()['test_data_'+str(i+1)].columns = ['user', 'item']\n",
    "    globals()['test_data_'+str(i+1)] = globals()['test_data_'+str(i+1)].values.tolist()\n",
    "\n",
    "    globals()['val_data_'+str(i+1)] = globals()['val_fold_'+str(i+1)][['uid','sid']].copy()\n",
    "    globals()['val_data_'+str(i+1)].columns = ['user', 'item']\n",
    "    globals()['val_data_'+str(i+1)] = globals()['val_data_'+str(i+1)].values.tolist()\n",
    "\n",
    "    globals()['all_mat_'+str(i+1)] = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
    "    for x in globals()['train_data_'+str(i+1)]: globals()['all_mat_'+str(i+1)][x[0], x[1]] = 1.0\n",
    "    for x in globals()['test_data_'+str(i+1)]:  globals()['all_mat_'+str(i+1)][x[0], x[1]] = 1.0\n",
    "    for x in globals()['val_data_'+str(i+1)]:   globals()['all_mat_'+str(i+1)][x[0], x[1]] = 1.0\n",
    "    for x in neg_samples_data:                  globals()['all_mat_'+str(i+1)][x[0], x[1]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77713410",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRData(data.Dataset):\n",
    "\tdef __init__(self, features,num_item, train_mat=None, total_mat=None, num_ng=0, is_training=None, sample_mode = None):\n",
    "\t\tsuper(BPRData, self).__init__()\n",
    "\t\t\"\"\" Note that the labels are only useful when training, we thus\n",
    "\t\t\tadd them in the ng_sample() function.\n",
    "\t\t\"\"\"\n",
    "\t\tself.features = features\n",
    "\t\tself.features2 = None\n",
    "\t\tself.num_item = num_item\n",
    "\t\tself.train_mat = train_mat\n",
    "\t\tself.total_mat = total_mat\n",
    "\t\tself.num_ng = num_ng\n",
    "\t\tself.is_training = is_training\n",
    "\t\tself.sample_mode = sample_mode\n",
    "\t\t# self.labels = [0 for _ in range(len(features))]\n",
    "\n",
    "\tdef ng_sample(self):\n",
    "\t\t### sample 2 pos, 2 neg\n",
    "\n",
    "\t\tif True:\n",
    "\t\t\tassert self.is_training, 'no need to sampling when testing'\n",
    "\t\t\tself.features_fill = []\n",
    "\n",
    "\t\t\t### add neg\n",
    "\t\t\t### random sample until neg is not from total_mat\n",
    "\t\t\t### note total_mat includes train, val, test, (test neg_samples)\n",
    "\t\t\tfor x in self.features:\n",
    "\t\t\t\tu, pos = x[0], x[1]\n",
    "\t\t\t\tfor t in range(self.num_ng):\n",
    "\t\t\t\t\tneg = np.random.randint(self.num_item, size = 1) ; neg = neg[0]\n",
    "\t\t\t\t\twhile (u, neg) in self.total_mat:\n",
    "\t\t\t\t\t\tneg = np.random.randint(self.num_item, size = 1) ; neg = neg[0]\n",
    "\t\t\t\t\tself.features_fill.append([u, pos, neg])\n",
    "\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.num_ng * len(self.features) if self.is_training else len(self.features)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tfeatures = self.features_fill if self.is_training else self.features\n",
    "\n",
    "\t\tif True:\n",
    "\t\t\tuser = features[idx][0]\n",
    "\t\t\tpos = features[idx][1]\n",
    "\t\t\tneg = features[idx][2]\n",
    "\t\t\treturn user, pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174db2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(name): globals()['train_dataset_'+str(i+1)] = BPRData(globals()['train_data_'+str(i+1)], \\\n",
    "                                                                         item_num, \\\n",
    "                                                                         globals()['train_mat_'+str(i+1)], \\\n",
    "                                                                         globals()['all_mat_'+str(i+1)], \\\n",
    "                                                                         num_ng = 1, \\\n",
    "                                                                         is_training = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2fb8648",
   "metadata": {},
   "source": [
    "#### Generate Epoch Training Data for Faster, Reproducible Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231cc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(0)\n",
    "total_epochs = 20\n",
    "num_ng = 3\n",
    "import pickle\n",
    "for i in range(name):\n",
    "    path = f'./train_samples_'+str(i+1)\n",
    "    os.mkdir(path)\n",
    "    print('train '+str(i+1))\n",
    "    for e in range(total_epochs):\n",
    "        print(e)\n",
    "        train_list = []\n",
    "        for j in range(num_ng):\n",
    "            globals()['train_dataset_'+str(i+1)].ng_sample()\n",
    "            train_samples = globals()['train_dataset_'+str(i+1)].features_fill\n",
    "            train_list += train_samples\n",
    "        with open(path+f'/train_samples_{e}', 'wb') as fp:\n",
    "            pickle.dump(train_list, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
